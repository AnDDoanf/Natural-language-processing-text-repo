{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnDDoanf/learn_NLP/blob/master/notebooks/Programming_Assignment_4_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Named Entity Recognition with MIT Restaurant Dataset\n",
        "\n",
        "Your name: Nguyen Van A\n",
        "\n",
        "Student ID: USTH001\n",
        "\n",
        "**Due: 23:59 19/3/2023**\n",
        "\n",
        "## Task Description\n",
        "\n",
        "In this assignment, you will train a NER Model using Conditional Random Fields (CRF) on and report the accuracy of your model on the test dataset.\n",
        "\n",
        "You will use the [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset to do the task.\n",
        "\n",
        "## How to submit\n",
        "\n",
        "- Attach notebook file (.ipynb) and submit your work to Google Class Room \n",
        "- Name your file as YourName_StudentID_Assignment4.ibynb. E.g., Nguyen_Van_A_ST099834_Assignment4.ipynb\n",
        "- Write your name and student ID into this notebook\n",
        "- Copying others' assignments is strictly prohibited.\n"
      ],
      "metadata": {
        "id": "PGcNXgEH9S3s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install python-crfsuite"
      ],
      "metadata": {
        "id": "7-wE5Ygy_851"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q python-crfsuite"
      ],
      "metadata": {
        "id": "qhjb-9J2AAMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd3e9515-4265-4cc0-de86-5fb6851b1f48"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.0 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "26ieJ1aEAQs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "import pycrfsuite"
      ],
      "metadata": {
        "id": "yGewX5VmASAU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "We will use [MIT Restaurant Dataset](https://groups.csail.mit.edu/sls/downloads/restaurant/) dataset.\n",
        "\n",
        "The data set is already in CoNLL format. We will use the [train](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio) data to create the NER model and evaluate the model on the [test](https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio) data."
      ],
      "metadata": {
        "id": "Ie-POGzEv8xA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download data"
      ],
      "metadata": {
        "id": "2U0ME8SbxIS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -f restauranttrain.bio\n",
        "!rm -f restauranttest.bio\n",
        "\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttest.bio\n",
        "!wget https://groups.csail.mit.edu/sls/downloads/restaurant/restauranttrain.bio"
      ],
      "metadata": {
        "id": "PcFJBAy7xa-x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data (30 points)\n",
        "\n",
        "In this part, you will load a data file into a list of sentences. Each sentence is a list of (word, tag) tuples.\n",
        "\n",
        "**Note: Blank lines are used to seperate sentences.**\n",
        "\n",
        "For instance, the sentence below will be loaded into a list\n",
        "\n",
        "```\n",
        "O\ta\n",
        "B-Rating\tfour\n",
        "I-Rating\tstar\n",
        "O\trestaurant\n",
        "B-Location\twith\n",
        "I-Location\ta\n",
        "B-Amenity\tbar\n",
        "```\n",
        "\n",
        "You will complete the function below"
      ],
      "metadata": {
        "id": "MLyiSFarytjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Add necessary import here\n",
        "\n",
        "def load_data(file_path):\n",
        "    \"\"\"Load data into a list of list of (word, tag) tuples\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to data\n",
        "\n",
        "    Returns:\n",
        "        sentences: list of (word, tag) tuples\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    \n",
        "    #TODO: Write your code here\n",
        "    words = []\n",
        "    tags = []\n",
        "    for line in open(file_path, \"r\"):\n",
        "      sentence = line.rstrip(\"\\n\").split(\"\\t\")\n",
        "      if sentence[0] == '':\n",
        "        sentences.append([tuple(words), tuple(tags)])\n",
        "        words = []\n",
        "        tags = []\n",
        "        continue\n",
        "      words.append(sentence[1])\n",
        "      tags.append(sentence[0])\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "M6UmjUBP06c4"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents = load_data('restauranttrain.bio')\n",
        "test_sents = load_data('restauranttest.bio')"
      ],
      "metadata": {
        "id": "zy6fIDnF19nC"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the number of sentences in train and test data"
      ],
      "metadata": {
        "id": "oOzFyaKo2Wgl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_sents)"
      ],
      "metadata": {
        "id": "jVdNqwKH2mi8",
        "outputId": "75dd577c-e847-476c-f0a5-71cfbc84c4c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7660"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_sents)"
      ],
      "metadata": {
        "id": "sVVcSv6r2oq6",
        "outputId": "9f3d1b75-b918-4b02-fd8e-d06a2a7ab075",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1521"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents[2]"
      ],
      "metadata": {
        "id": "Msy21RWM232U",
        "outputId": "a54245b2-ba82-4c63-da37-0d4c1787b1c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('5', 'star', 'resturants', 'in', 'my', 'town'),\n",
              " ('B-Rating', 'I-Rating', 'O', 'B-Location', 'I-Location', 'I-Location')]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Features (50 points)\n",
        "\n",
        "We can extract as many features as you want. You will implement following basic features.\n",
        "\n",
        "※ Of course, you can add more features.\n",
        "\n",
        "*Word identity (lowercase)*\n",
        "\n",
        "- Previous word identity\n",
        "- Current word identity\n",
        "- Next word\n",
        "- Previous word and current word combination. Concat the previous word the current word by '||'\n",
        "- Current word and next word combination. Concat two words by '||'\n",
        "\n",
        "*Word shapes*\n",
        "\n",
        "- Word prefix and suffix (4 characters)\n",
        "- The first character of the current word is the capital letter\n",
        "\n",
        "**All you need to do is to complete the function `word2feature`.**"
      ],
      "metadata": {
        "id": "FVv2iYez3CBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word2features(sentence, i):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        sentence (list): list of words [w1, w2,...,w_n]\n",
        "        i (int): index of the word\n",
        "    Return:\n",
        "        features (dict): dictionary of features\n",
        "    \"\"\"\n",
        "    word = sentence[i].lower()\n",
        "    prev_word = '' if i==0 else sentence[i-1].lower()\n",
        "    next_word = '' if i==len(sentence)-1 else sentence[i+1].lower()\n",
        "    features = {\n",
        "        #TODO: Write your features here\n",
        "        'word': word,\n",
        "        'prev_word': prev_word,\n",
        "        'next_word': next_word,\n",
        "        'prev_cur_word': prev_word+\"||\"+word,\n",
        "        'cur_next_word': word+\"||\"+next_word,\n",
        "        'prefix': word[:4],\n",
        "        'suffix': word[-4:],\n",
        "        'cap_letter': word[0]\n",
        "    }\n",
        "    \n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of words [w1, w2,...,w_n]\n",
        "    \"\"\"\n",
        "    return [word2features(sentence, i) for i in range(len(sentence))]\n",
        "\n",
        "\n",
        "def sent2labels(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"    \n",
        "    return [tag for token, tag in sentence]\n",
        "\n",
        "def untag(sentence):\n",
        "    \"\"\"\n",
        "    sentence is a list of tuples (word, postag)\n",
        "    \"\"\"\n",
        "    return [token for token,_ in sentence]"
      ],
      "metadata": {
        "id": "yfBAsejb5iir"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to extract features for the first sentence"
      ],
      "metadata": {
        "id": "t7fSWZJQ83Vx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sents[0]"
      ],
      "metadata": {
        "id": "iNrn8zBrS-Sa",
        "outputId": "691e539e-b95b-442a-fc9d-3111efc50392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('2', 'start', 'restaurants', 'with', 'inside', 'dining'),\n",
              " ('B-Rating', 'I-Rating', 'O', 'O', 'B-Amenity', 'I-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent2features(untag(train_sents)[0])[2]"
      ],
      "metadata": {
        "id": "KFTpTYO68tfD",
        "outputId": "dca00b14-2678-4932-b1af-9d23fda4de0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'word': 'restaurants',\n",
              " 'prev_word': 'start',\n",
              " 'next_word': 'with',\n",
              " 'prev_cur_word': 'start||restaurants',\n",
              " 'cur_next_word': 'restaurants||with',\n",
              " 'prefix': 'rest',\n",
              " 'suffix': 'ants',\n",
              " 'cap_letter': 'r'}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create train/test data"
      ],
      "metadata": {
        "id": "9Xl5Tyd4-zZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent2features(untag(train_sents)[s]) for s in range(len(train_sents))]\n",
        "y_train = sent2labels(train_sents)\n",
        "\n",
        "X_test = [sent2features(untag(test_sents)[s]) for s in range(len(test_sents))]\n",
        "y_test = sent2labels(test_sents)"
      ],
      "metadata": {
        "id": "nKUVYzMQ-3ef"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "La08Oyam_ZjN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer = pycrfsuite.Trainer(verbose=False)\n",
        "\n",
        "for xseq, yseq in zip(X_train, y_train):\n",
        "    trainer.append(xseq, yseq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-C-fq8x_brV",
        "outputId": "e5821855-3a12-4436-8a7d-9389ad36cbbb"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 707 ms, sys: 5.11 ms, total: 712 ms\n",
            "Wall time: 727 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Set model parameters\n",
        "\n",
        "max_iterations = 50 #@param[50, 20, 100]\n",
        "\n",
        "trainer.set_params({\n",
        "    'c1': 1.0,   # coefficient for L1 penalty\n",
        "    'c2': 1e-3,  # coefficient for L2 penalty\n",
        "    'max_iterations': max_iterations,\n",
        "\n",
        "    # include transitions that are possible, but not observed\n",
        "    'feature.possible_transitions': True\n",
        "})"
      ],
      "metadata": {
        "id": "C0XJtpOtO2Pl"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "trainer.train('mitrestaurant.crfsuite')"
      ],
      "metadata": {
        "id": "v5VXTKZdO4aU",
        "outputId": "e5848fd4-4993-4d03-be58-67bcd083456c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.61 s, sys: 12.2 ms, total: 6.62 s\n",
            "Wall time: 6.64 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation (20 points)\n",
        "\n",
        "We will use [seqeval](https://github.com/chakki-works/seqeval) package for evaluation NER result."
      ],
      "metadata": {
        "id": "wQQLY7m-PPmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q seqeval[cpu]"
      ],
      "metadata": {
        "id": "GtpO8Mb4dFMg"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions"
      ],
      "metadata": {
        "id": "6UCqdlNvPWZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tagger = pycrfsuite.Tagger()\n",
        "tagger.open('mitrestaurant.crfsuite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVenrYzcPYoM",
        "outputId": "cc5ce6df-b906-4fc6-cbbd-d5345eff88cb"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.closing at 0x7f80982fddf0>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_sent = test_sents[0]\n",
        "example_sent"
      ],
      "metadata": {
        "id": "rAfV8QhcPb9e",
        "outputId": "52329eb9-0a15-402c-e577-50c245947933",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'four', 'star', 'restaurant', 'with', 'a', 'bar'),\n",
              " ('O', 'B-Rating', 'I-Rating', 'O', 'B-Location', 'I-Location', 'B-Amenity')]"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted:\", ' '.join(tagger.tag(sent2features( example_sent[0]))))\n",
        "print(\"Correct:  \", ' '.join(example_sent[1]))"
      ],
      "metadata": {
        "id": "8hGrDn-4P55R",
        "outputId": "cf6d3a2d-ba59-451b-d75e-8980f292c51a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: O B-Rating I-Rating O O O B-Amenity\n",
            "Correct:   O B-Rating I-Rating O B-Location I-Location B-Amenity\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "y_pred = [tagger.tag(xseq) for xseq in X_test]"
      ],
      "metadata": {
        "id": "3ee18ZKIQqgU",
        "outputId": "5f677ab6-9387-4293-b2b7-d2edc528cb5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 135 ms, sys: 1.71 ms, total: 137 ms\n",
            "Wall time: 145 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert(tuples):\n",
        "    return [*tuples, ]\n",
        "y_test_list = []\n",
        "for i in range(len(y_test)):\n",
        "  new_y_test = convert(y_test[i])\n",
        "  y_test_list.append(new_y_test)"
      ],
      "metadata": {
        "id": "TqiNv4u3zkBM"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_list, y_pred))"
      ],
      "metadata": {
        "id": "Ns2UeFU5U96O",
        "outputId": "b4c632a9-defd-41ae-9414-35a278e31ffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        Amenity       0.70      0.65      0.67       533\n",
            "        Cuisine       0.84      0.81      0.82       532\n",
            "           Dish       0.76      0.72      0.74       288\n",
            "          Hours       0.71      0.65      0.68       212\n",
            "       Location       0.83      0.80      0.82       812\n",
            "          Price       0.81      0.81      0.81       171\n",
            "         Rating       0.78      0.77      0.77       201\n",
            "Restaurant_Name       0.77      0.73      0.75       402\n",
            "\n",
            "      micro avg       0.78      0.75      0.77      3151\n",
            "      macro avg       0.77      0.74      0.76      3151\n",
            "   weighted avg       0.78      0.75      0.77      3151\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# References\n",
        "\n",
        "1. Datasets for Entity Recognition: https://github.com/juand-r/entity-recognition-datasets\n",
        "2. [sklearn-crfsuite tutorial](https://sklearn-crfsuite.readthedocs.io/en/latest/tutorial.html#let-s-use-conll-2002-data-to-build-a-ner-system). \n",
        "3. [Quick Recipe: Build a POS tagger using a Conditional Random Field](https://nlpforhackers.io/crf-pos-tagger/)\n",
        "4. [NLP Guide: Identifying Part of Speech Tags using Conditional Random Fields](https://medium.com/analytics-vidhya/pos-tagging-using-conditional-random-fields-92077e5eaa31)\n",
        "5. [CRFsuite - Tutorial on Chunking Task](http://www.chokkan.org/software/crfsuite/tutorial.html)"
      ],
      "metadata": {
        "id": "oRMhFCCEBhds"
      }
    }
  ]
}